# Awesome Neural Radience Field (NeRF) Editing [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A curated collection of resources for NeRF editing techniques.

## Recent research [Stay Tunedâ˜•]

- [2023]
  - [ICCV'23] [Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields](https://arxiv.org/pdf/2308.11974)
  - [Arxiv] [Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views](https://arxiv.org/pdf/2308.11198)
  - [Arxiv] [Watch Your Steps: Local Image and Scene Editing by Text Instructions](https://arxiv.org/pdf/2308.08947)
  - [Arxiv] [Focused Specific Objects NeRF](https://arxiv.org/pdf/2308.05970)
  - [ICCV'23] [Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis](https://arxiv.org/pdf/2308.02840)
  - [ACM MM'23] [Context-Aware Talking-Head Video Editing](https://arxiv.org/pdf/2308.00462)
  - [ICCV'23] Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields
  - [Arxiv] Dyn-E: Local Appearance Editing of Dynamic Neural Radiance Fields
  - [Arxiv] FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural Radiance Fields
  - [Arxiv] DreamEditor: Text-Driven 3D Scene Editing with Neural Fields
  - [Arxiv] Car-Studio: Learning Car Radiance Fields from Single-View and Endless In-the-wild Images
  - [Arxiv] Edit-DiffNeRF: Editing 3D Neural Radiance Fields using 2D Diffusion Model
  - [Arxiv] Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with Instructions
  - [Arxiv] Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields
  - [CVPR'23] Local 3D Editing via 3D Distillation of CLIP Knowledge
  - [Arxiv] Edit-DiffNeRF: Editing 3D Neural Radiance Fields using 2D Diffusion Model
  - [Arxiv] DORSal: Diffusion for Object-centric Representations of Scenes et al.
  - [Arxiv] UrbanIR: Large-Scale Urban Scene Inverse Rendering from a Single Video
  - [IJCAI'23] RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models
  - [Arxiv] FDNeRF: Semantics-Driven Face Reconstruction, Prompt Editing and Relighting with Diffusion Models
  - [Arxiv] AvatarStudio: Text-driven Editing of 3D Dynamic Human Head Avatars
  - [Arxiv] PlaNeRF: SVD Unsupervised 3D Plane Regularization for NeRF Large-Scale Scene Reconstruction
  - [Arxiv] InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance Fields
  - [Arxiv] OR-NeRF: Object Removing from 3D Scenes Guided by Multiview Segmentation with Neural Radiance Fields
  - [CVPR'23] NeuralEditor: Editing Neural Radiance Fields via Manipulating Point Clouds
  - [Arxiv] Unsupervised Object-Centric Voxelization for Dynamic Scene Understanding
  - [Arxiv] NaviNeRF: NeRF-based 3D Representation Disentanglement by Latent Semantic Navigation
  - [Arxiv] Reference-guided Controllable Inpainting of Neural Radiance Fields
  - [Arxiv] UVA: Towards Unified Volumetric Avatar for View Synthesis, Pose rendering, Geometry and Texture Editing
  - [Arxiv] PVD-AL: Progressive Volume Distillation with Active Learning for Efficient Conversion Between Different NeRF Architectures
  - [ICCV'23] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior
  - [Arxiv] VMesh: Hybrid Volume-Mesh Representation for Efficient View Synthesis
  - [Arxiv] CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout
  - [Arxiv] TEGLO: High Fidelity Canonical Texture Mapping from Single-View Images
  - [Arxiv] Set-the-Scene: Global-Local Training for Generating Controllable NeRF Scenes
  - [CVPR'23] SINE: Semantic-driven Image-based NeRF Editing with Prior-guided Editing Field
  - [CVPR'23-Highlight] Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization
  - [Arxiv] Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions
  - [Arxiv] Interactive Geometry Editing of Neural Radiance Fields
  - [Arxiv] SKED: Sketch-guided Text-based 3D Editing
  - [CVPR'23] PartNeRF: Generating Part-Aware Editable 3D Shapes without 3D Supervision
  - [Arxiv] I^2-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs
  - [CVPR'23] Frequency-Modulated Point Cloud Rendering with Easy Editing
  - [Arxiv] MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field
  - [CVPR'23] Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene Representation from 2D Supervision
  - [Arxiv] IntrinsicNGP: Intrinsic Coordinate based Hash Encoding for Human NeRF
  - [Arxiv] LC-NeRF: Local Controllable Face Generation in Neural Randiance Field
  - [Arxiv] In-N-Out: Face Video Inversion and Editing with Volumetric Decomposition
  - [AAAI'23-Oral] Semantic 3D-aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field
  - [ICML'23] Equivariant Architectures for Learning in Deep Weight Spaces
  - [Arxiv] RecolorNeRF: Layer Decomposed Radiance Fields for Efficient Color Editing of 3D Scenes
  - [ICCV'23] MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos

- [2022]
  - [Arxiv] MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos
  - [Arxiv] PaletteNeRF: Palette-based Color Editing for NeRFs
  - [Arxiv] Removing Objects From Neural Radiance Fields
  - [Arxiv] PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields
  - [Arxiv] Rodin: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion
  - [Arxiv] EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points
  - [Arxiv] NeRFEditor: Differentiable Style Decomposition for Full 3D Scene Editing
  - [Arxiv] SSDNeRF: Semantic Soft Decomposition of Neural Radiance Fields
  - [AAAI'23] One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation
  - [Arxiv] ClimateNeRF: Extreme Weather Synthesis in Neural Radiance Field
  - [CVPR'23] SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural Radiance Fields
  - [Arxiv] ONeRF: Unsupervised 3D Object Segmentation from Multiple Views
  - [Arxiv] FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields
  - [Arxiv] NeRFFaceEditing: Disentangled Face Editing in Neural Radiance Fields
  - [Arxiv] Learning-based Inverse Rendering of Complex Indoor Scenes with Differentiable Monte Carlo Raytracing
  - [Arxiv] 3D GAN Inversion with Pose Optimization
  - [Arxiv] Controllable Radiance Fields for Dynamic Face Synthesis
  - [SIGGRAPH Asia'22] Reconstructing Personalized Semantic Facial NeRF Models From Monocular Video
  - [Arxiv] Estimating Neural Reflectance Field from Radiance Field using Tree Structures
  - [Arxiv] IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis
  - [Arxiv] Unsupervised Multi-View Object Segmentation Using Radiance Field Propagation
  - [PG'22 & CGF] Generative Deformable Radiance Fields for Disentangled Image Synthesis of Topology-Varying Objects
  - [3DV'22-Oral] Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations
  - [SIGGRAPH Asia'22] FDNeRF: Few-shot Dynamic Neural Radiance Fields for Face Reconstruction and Expression Editing
  - [ECCV'22] Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for Editable Portrait Image Synthesis
  - [Arxiv] PS-NeRF: Neural Inverse Rendering for Multi-view Photometric Stereo        
  - [Arxiv] RigNeRF: Fully Controllable Neural 3D Portraits
  - [Arxiv] NeRF-In: Free-Form NeRF Inpainting with RGB-D Priors
  - [Arxiv] ObPose: Leveraging Pose for Object-Centric Scene Inference and Generation in 3D
  - [NeurIPS'22] Decomposing NeRF for Editing via Feature Field Distillation
  - [CVPR'22] NeRF-Editing: Geometry Editing of Neural Radiance Fields
  - [Arxiv] Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation
  - [Arxiv] Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation
  - [Arxiv] ERF: Explicit Radiance Field Reconstruction From Scratch
  - [Arxiv] NeuVV: Neural Volumetric Videos with Immersive Rendering and Editing

- [2021]
  - [ECCV'22] NeRF for Outdoor Scene Relighting
  - [CVPR'22] CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields
  - [Arxiv] Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields
  - [ECCV'22] MoFaNeRF: Morphable Facial Neural Radiance Field
  - [CVPR'22] NeRFReN: Neural Radiance Fields with Reflections
  - [Arxiv] FENeRF: Face Editing in Neural Radiance Fields
  - [Arxiv] DIVeR: Real-time and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering
  - [Arxiv] StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis
  - [Arxiv] Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering
  - [ICCV'21] CodeNeRF: Disentangled Neural Radiance Fields for Object Categories
  - [SIGGRAPH Asia'21] NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination
  - [Arxiv] Unsupervised Discovery of Object Radiance Fields
  - [Arxiv] Editing Conditional Radiance Fields
  - [Arxiv] Editable Free-viewpoint Video Using a Layered Neural Representation
 
- [2020]
  - [Arxiv] Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video
  - [Arxiv] Neural Sparse Voxel Fields

- [datasets]
  - [Dataset 1 name and link]
  - [Dataset 2 name and link]
  - ...

- [Useful tools and software]
  - [Tool 1 name and link]
  - [Tool 2 name and link]
  - ...

## Contributing

We welcome contributions to expand and improve this collection. If you have relevant resources to share or want to collaborate on this project, please follow these guidelines:

1. Fork this repository.
2. Add your resources to the appropriate sections in the README.
3. Commit your changes.
4. Push to the branch: `git push origin master`.
5. Submit a pull request.

Please ensure that the resources you contribute are relevant to NeRF-based editing techniques.

## License

This project is licensed under the MIT License.

---

Feel free to explore, contribute, and collaborate. Together, we can build a valuable resource for the 3D aware editing community! If you have any questions, want to collaborate, or need assistance, please don't hesitate to reach out liweize0224@gmail.com.
